{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math,torch,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from n_framework import *\n",
    "\n",
    "from fastprogress import progress_bar,master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import torchvision.transforms.functional as TF\n",
    "from contextlib import contextmanager\n",
    "from torch import nn,tensor\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "from n_framework import *\n",
    "import logging\n",
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab720155e10f4f09a93416a6d0d8c2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = 'image','label'\n",
    "name = 'fashion_mnist'\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[x]=[torch.flatten(TF.to_tensor(o))for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=1024\n",
    "tds = dsd.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, torch.Tensor): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)\n",
    "\n",
    "def collate_device(b): return to_device(default_collate(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DataLoaders:\n",
    "    def __init__(self,*dls): self.train,self.valid = dls[:2]\n",
    "    @classmethod\n",
    "    def from_dd(cls,dd,batch_size, as_tuple=True):\n",
    "        #return cls(*[DataLoader(ds, batch_size,num_workers=4, collate_fn=collate_dict(ds)) for ds in dd.values()])\n",
    "        return cls(*[DataLoader(ds, batch_size, collate_fn=collate_dict(ds)) for ds in dd.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 784]), tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders.from_dd(tds,bs)\n",
    "dt = dls.train\n",
    "xb,yb = next(iter(dt))\n",
    "xb.shape,yb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, loss_func, lr, opt_func=optim.SGD): fc.store_attr()\n",
    "\n",
    "    def one_batch(self):\n",
    "        self.xb,self.yb = to_device(self.batch)\n",
    "        self.preds = self.model(self.xb)\n",
    "        self.loss = self.loss_func(self.preds, self.yb)\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        with torch.no_grad(): self.calc_stats()\n",
    "\n",
    "    def calc_stats(self):\n",
    "        acc = (self.preds.argmax(dim=1)==self.yb).float().sum()\n",
    "        self.accs.append(acc)\n",
    "        n = len(self.xb)\n",
    "        self.losses.append(self.loss*n)\n",
    "        self.ns.append(n)\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num,self.batch in enumerate(dl): self.one_batch()\n",
    "        n = sum(self.ns)\n",
    "        print(self.epoch, self.model.training, sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.accs,self.losses,self.ns = [],[],[]\n",
    "        self.model.to(def_device)\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        self.n_epochs = n_epochs\n",
    "        for self.epoch in range(n_epochs):\n",
    "            self.one_epoch(True)\n",
    "            with torch.no_grad(): self.one_epoch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,nh =28*28,50\n",
    "model = nn.Sequential(nn.Linear(m,nh),nn.ReLU(),nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.18521953125 0.59565\n",
      "0 False 1.1349697544642856 0.6088142857142858\n",
      "CPU times: user 9.02 s, sys: 211 ms, total: 9.23 s\n",
      "Wall time: 9.79 s\n"
     ]
    }
   ],
   "source": [
    "#When the num_workers=0/4/8 the time it took largely changes \n",
    "learn = Learner(model,dls, F.cross_entropy, lr=0.2)\n",
    "%time learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Callback Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def identity(*args):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    if not args:return\n",
    "    x,*args = args\n",
    "    return (x,)+tuple(args) if args else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, '4', 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity(3,'4',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_cbs(cbs,method_nm,learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None:method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class callback(): order=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletionCallback(callback):\n",
    "    def before_fit(self): self.count= 0\n",
    "    def after_batch(self): self.count += 1\n",
    "    def after_fit(self): print(f'Completed {self.count} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n"
     ]
    }
   ],
   "source": [
    "cbs = [CompletionCallback()]\n",
    "run_cbs(cbs, 'before_fit')\n",
    "run_cbs(cbs, 'after_batch')\n",
    "run_cbs(cbs, 'after_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CompletionCallback>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = cbs[0];cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n"
     ]
    }
   ],
   "source": [
    "getattr(cb, 'after_fit', None)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class with_cbs:\n",
    "    def __init__(self,nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o,*args,**kwargs):\n",
    "            try:\n",
    "                o.callback(f\"before_{self.nm}\")\n",
    "                f(o,*args,**kwargs)\n",
    "                o.callback(f\"After_{self.nm}\")\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']:pass\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, loss_func, lr, cbs,opt_func=optim.SGD): \n",
    "        fc.store_attr()\n",
    "        for cb in cbs: cb.learn = self\n",
    "\n",
    "    def one_batch(self):\n",
    "        self.preds = self.model(self.batch[0])\n",
    "        self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        try:\n",
    "            self.callback('before_epoch')            \n",
    "            for self.iter,self.batch in enumerate(self.dl): \n",
    "                try:\n",
    "                    self.callback('before_batch')\n",
    "                    self.one_batch()\n",
    "                    self.callback('after_batch')\n",
    "                except CancelBatchException:pass\n",
    "            self.callback('after_epoch')\n",
    "        except CancelEpochException:pass\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        try:\n",
    "            self.callback('before_fit')\n",
    "            for self.epoch in self.epochs:\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "            self.callback('after_fit')\n",
    "        except CancelFitException:pass\n",
    "\n",
    "    def callback(self,method_nm): run_cbs(self.cbs,method_nm,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,nh = 28*28,50\n",
    "def get_model(): return nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCallback(callback):\n",
    "    order =1\n",
    "    def after_batch(self): raise CancelEpochException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 69 batches\n",
      "CPU times: user 8.17 s, sys: 180 ms, total: 8.35 s\n",
      "Wall time: 8.55 s\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(get_model(),dls, F.cross_entropy, lr=0.2, cbs=[DeviceCB(),CompletionCallback()])\n",
    "%time learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeviceCb(callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self): self.learn.model.to(self.device)\n",
    "    def before_batch(self): self.learn.batch = to_device(self.learn.batch,device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceCB(callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Metric:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self): self.vals, self.ns = [],[]\n",
    "    def add(self,inp, targ=None, n=1): # n is the number of items in the mini-batch.\n",
    "        self.last = self.calc(inp,targ)\n",
    "        self.vals.append(self.last)\n",
    "        self.ns.append(n)\n",
    "    @property\n",
    "    def value(self):\n",
    "        ns = tensor(self.ns)\n",
    "        return (tensor(self.vals)*ns).sum()/ns.sum()\n",
    "    def calc(self, inps,targs): return inps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Accuracy(Metric):\n",
    "    def calc(self,inps,targs): return (inps==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.45)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "acc.add(tensor([0,1,2,0,1,2]),tensor([0,1,1,2,1,0]))\n",
    "acc.add(tensor([1,1,2,0,1]),tensor([0,1,1,2,1]))\n",
    "acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.62), 0.62)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=Metric()\n",
    "loss.add(0.6,n=32)\n",
    "loss.add(0.9,n=2)\n",
    "loss.value,round((0.6*32+0.9*2)/(32+2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.50)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = MulticlassAccuracy()\n",
    "metric.update(tensor([0,2,1,3]), tensor([0,1,2,3]))\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.reset()\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_cpu(x):\n",
    "    if isinstance(x,Mapping): return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x,list): return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): return tuple(to_cpu(list(x)))\n",
    "    return x.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetricsCB(callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms:metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "    def _log(self,d): print(d)\n",
    "    def before_fit(self): self.learn.metrics = self\n",
    "    def before_epoch(self): [o.reset() for o in self.all_metrics.values()]\n",
    "    def after_epoch(self):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = self.learn.epoch\n",
    "        log['train'] = self.learn.model.training\n",
    "        self._log(log)\n",
    "    \n",
    "    def after_batch(self):\n",
    "        x,y = to_cpu(self.learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(self.learn.preds),y)\n",
    "        self.loss.update(to_cpu(self.learn.loss),weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': '0.617', 'loss': '1.165', 'epoch': 0, 'train': True}\n",
      "{'accuracy': '0.697', 'loss': '0.816', 'epoch': 0, 'train': False}\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "learn = Learner(model,dls,F.cross_entropy, lr=0.2, cbs=[DeviceCB(),metrics])\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MulticlassAccuracy': '0.611', 'loss': '1.163', 'epoch': 0, 'train': True}\n",
      "{'MulticlassAccuracy': '0.692', 'loss': '0.815', 'epoch': 0, 'train': False}\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "metrics = MetricsCB(MulticlassAccuracy())\n",
    "learn = Learner(model,dls,F.cross_entropy, lr=0.2, cbs=[DeviceCB(),metrics])\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Learner():\n",
    "    def __init__(self,model,dls,loss_func,lr,cbs, opt_func= optim.SGD):\n",
    "        fc.store_attr()\n",
    "        for cb in cbs: cb.learn =self\n",
    "     \n",
    "    @contextmanager\n",
    "    def callback_ctx(self,nm):\n",
    "        try:\n",
    "            self.callback(f'before_{nm}')\n",
    "            yield\n",
    "            self.callback(f'after_{nm}')\n",
    "        #except globals()[f'Cancel{nm.title()}Exception']:pass\n",
    "        except globals()[f'Cancel{nm.title()}Exception']: pass\n",
    "        finally: self.callback(f'cleanup_{nm}')\n",
    "    \n",
    "    def one_epoch(self,train):\n",
    "        self.model.train(train)\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        with self.callback_ctx('epoch'):\n",
    "            for self.iter,self.batch in enumerate(self.dl):\n",
    "                 with self.callback_ctx('batch'):\n",
    "                        self.predict()\n",
    "                        self.get_loss()\n",
    "                        if self.model.training:\n",
    "                            self.backward()\n",
    "                            self.step()\n",
    "                            self.zero_grad()\n",
    "                 \n",
    "    def fit(self,n_epochs):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(),self.lr)\n",
    "        with self.callback_ctx('fit'):\n",
    "            for self.epoch in self.epochs:\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "    \n",
    "#     def __getattr__(self,name):\n",
    "#         if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback,name)\n",
    "#         raise AttributeError(name)\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    \n",
    "    def callback(self,method_nm): run_cbs(self.cbs,method_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrainCb(callback):\n",
    "    \n",
    "    def predit(self): self.learn.preds = self.learn.model(self.learn.batch[0])\n",
    "    def get_loss(self): self.learn.loss = self.learn.loss_func(self.learn.preds,self.learn.batch[1])\n",
    "    def backward(self): self.learn.loss.backward()\n",
    "    def step(self): self.learn.opt.step()\n",
    "    def zero_grad(self): self.learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCB(callback):\n",
    "    def __init__(self, n_inp=1): self.n_inp = n_inp\n",
    "    def predict(self, learn): learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "    def get_loss(self, learn): learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressCb(callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self,plot=False): self.plot = plot\n",
    "    def before_fit(self):\n",
    "        self.learn.epochs = self.mbar = master_bar(self.learn.epochs)\n",
    "        if hasattr(self.learn,'metrics'): self.learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "    def _log(self,d): self.mbar.write(d)\n",
    "    def before_epoch(self): self.learn.dl = progress_bar(self.learn.dl,leave =False, parent=self.mbar)\n",
    "    def after_batch(self):\n",
    "        self.learn.dl.comment = f'{self.learn.loss:.3f}'\n",
    "        if self.plot and hasattr(self.learn,'metrics') and self.learn.model.training:\n",
    "            self.losses.append(self.learn.loss.item())\n",
    "            self.mbar.update_graph([[fc.L.range(self.losses),self.losses]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressCB(callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): self.plot = plot\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "\n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses: self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "    \n",
    "    def after_epoch(self, learn): \n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'): \n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph([[fc.L.range(self.losses), self.losses],[fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/59 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TrainCB.predict() missing 1 required positional argument: 'learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cbs \u001b[38;5;241m=\u001b[39m [TrainCB(),DeviceCB(),metrics, ProgressCb(plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m      3\u001b[0m learn \u001b[38;5;241m=\u001b[39m Learner(model, dls, F\u001b[38;5;241m.\u001b[39mcross_entropy, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, cbs\u001b[38;5;241m=\u001b[39mcbs)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[123], line 36\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_ctx(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_epoch(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[123], line 23\u001b[0m, in \u001b[0;36mLearner.one_epoch\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl):\n\u001b[1;32m     22\u001b[0m      \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_ctx(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss()\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining:\n",
      "Cell \u001b[0;32mIn[123], line 47\u001b[0m, in \u001b[0;36mLearner.callback\u001b[0;34m(self, method_nm)\u001b[0m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(\u001b[38;5;28mself\u001b[39m,method_nm): \u001b[43mrun_cbs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod_nm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[140], line 5\u001b[0m, in \u001b[0;36mrun_cbs\u001b[0;34m(cbs, method_nm, learn)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(cbs, key\u001b[38;5;241m=\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cb, method_nm, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainCB.predict() missing 1 required positional argument: 'learn'"
     ]
    }
   ],
   "source": [
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "cbs = [TrainCB(),DeviceCB(),metrics, ProgressCb(plot=True)]\n",
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2, cbs=cbs)\n",
    "learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learner():\n",
    "    def __init__(self,model,dls,loss_func,lr, cbs, opt_func=optim.SGD):\n",
    "        fc.store_attr()\n",
    "        for cb in cbs: cb.learn= self\n",
    "            \n",
    "    @with_cbs('batch')\n",
    "    def one_batch(self):\n",
    "        self.predit()\n",
    "        self.get_loss()\n",
    "        if self.model.training:\n",
    "            self.backward()\n",
    "            self.step()\n",
    "            self.zero_grad()\n",
    "    \n",
    "    def one_epoch(self,train):\n",
    "        self.model.train(train)\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        self._one_epoch()\n",
    "    \n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter, self.batch in enumerate(self.dl): self.one_epoch()\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(),lr)\n",
    "        self._fit()\n",
    "        \n",
    "    @with_cbs('fit')\n",
    "    def _fit(self):\n",
    "        for self.epoch in self.epochs:\n",
    "            self.one_epoch(True)\n",
    "            self.one_epoch(False)\n",
    "    \n",
    "    def __getattr__(self,name):\n",
    "        if name in('predict','get_loss', 'backward','step','zero_grad'): return partial(self.callback,name)\n",
    "        raise AttributeError(name)\n",
    "        \n",
    "    def callback(self,method_nm):\n",
    "        for cb in sorted(self.cbs, key=attrgetter('order')): getattr(cb,method_nm,identity)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "\n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "\n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter,self.batch in enumerate(self.dl): self._one_batch()\n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training)\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "\n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, train, valid):\n",
    "        for self.epoch in self.epochs:\n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "\n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        # `add_cb` and `rm_cb` were added in lesson 18\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            if lr is None: lr = self.lr\n",
    "            if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(train, valid)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)\n",
    "bs = 1024\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[x] = [TF.to_tensor(o) for o in b[x]]\n",
    "\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs)\n",
    "dt = dls.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni,nf,ks=3,act=True):\n",
    "    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res\n",
    "\n",
    "def cnn_layers():\n",
    "    return [ \n",
    "        conv(1,8, ks=5),  #14x14\n",
    "        conv(8,16),       #7x7\n",
    "        conv(16,32),      #4x4\n",
    "        conv(32,64),      #2x2\n",
    "        conv(64,10,act=False), #1x1\n",
    "        nn.Flatten()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
